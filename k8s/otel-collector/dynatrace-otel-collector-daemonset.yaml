apiVersion: opentelemetry.io/v1beta1
kind: OpenTelemetryCollector
metadata:
  name: dynatrace-logs
  namespace: dynatrace
spec:
  managementState: "managed"
  serviceAccount: collector
  envFrom:
    - secretRef:
        name: dynatrace-otelcol-dt-api-credentials
  env: # Add this section
    - name: KUBE_NODE_NAME # Add this environment variable
      valueFrom:
        fieldRef:
          apiVersion: v1
          fieldPath: spec.nodeName
    - name: MY_POD_IP
      valueFrom:
        fieldRef:
          apiVersion: v1
          fieldPath: status.podIP
  mode: "daemonset"
  image: "ghcr.io/dynatrace/dynatrace-otel-collector/dynatrace-otel-collector:latest"
  observability:
    metrics:
      enableMetrics: true
  resources:
    limits:
      memory: 1024Mi
  # mount host log directories to the otel collector container(s)
  volumes:
    - name: varlogpods
      hostPath:
        path: /var/log/pods
    - name: varlogcontainers
      hostPath:
        path: /var/log/containers
  volumeMounts:
    - name: varlogpods
      mountPath: /var/log/pods
      readOnly: true
    - name: varlogcontainers
      mountPath: /var/log/containers
      readOnly: true
  #
  config:
    receivers:
      prometheus:
        config:
          scrape_configs:
            - job_name: dynatrace-opentelemetry-collector-daemonset
              scrape_interval: 30s
              static_configs:
                - targets:
                    - ${MY_POD_IP}:8888
      otlp:
        protocols:
          grpc:
            endpoint: 0.0.0.0:4317
          http:
            endpoint: 0.0.0.0:4318
      filelog:
        include:
          - /var/log/pods/*/*/*.log
        exclude:
          - /var/log/pods/*/otc-container/*.log
          # - /var/log/pods/custom-otel-app_*/*/*.log
        start_at: beginning
        include_file_path: true
        include_file_name: false
        operators:
          # Add timestamp parsing at the start
          # - type: time_parser
          #   parse_from: attributes.time
          #   layout: "%Y-%m-%dT%H:%M:%S.%LZ"
          #   layout_type: strptime

          - type: router
            id: get-format
            routes:
              - output: parser-docker
                expr: 'body matches "^\\{"'
              - output: parser-crio
                expr: 'body matches "^[^ Z]+ "'
              - output: parser-containerd
                expr: 'body matches "^[^ Z]+Z"'
          # Parse CRI-O format
          - type: regex_parser
            id: parser-crio
            regex:
              "^(?P<time>[^ Z]+) (?P<stream>stdout|stderr) (?P<logtag>[^ ]*)
              ?(?P<log>.*)$"
            output: extract_metadata_from_filepath
            timestamp:
              parse_from: attributes.time
              layout_type: gotime
              layout: "2006-01-02T15:04:05.999999999Z07:00"
          # Parse CRI-Containerd format
          - type: regex_parser
            id: parser-containerd
            regex:
              "^(?P<time>[^ ^Z]+Z) (?P<stream>stdout|stderr) (?P<logtag>[^ ]*)
              ?(?P<log>.*)$"
            output: extract_metadata_from_filepath
            timestamp:
              parse_from: attributes.time
              layout_type: gotime
              layout: "2006-01-02T15:04:05.999999999Z07:00"
          # Parse Docker format
          - type: json_parser
            id: parser-docker
            output: extract_metadata_from_filepath
            timestamp:
              parse_from: attributes.time
              layout: "%Y-%m-%dT%H:%M:%S.%LZ"

          # Extract metadata from file path
          - type: regex_parser
            id: extract_metadata_from_filepath
            regex: '^.*\/(?P<namespace>[^_]+)_(?P<pod_name>[^_]+)_(?P<uid>[a-f0-9\-]{36})\/(?P<container_name>[^\._]+)\/(?P<restart_count>\d+)\.log$'
            parse_from: attributes["log.file.path"]
            cache:
              size: 128 # default maximum amount of Pods per Node is 110
          # Rename attributes
          - type: move
            from: attributes.log
            to: body
          - type: move
            from: attributes.stream
            to: attributes["log.iostream"]
          - type: move
            from: attributes.container_name
            to: resource["k8s.container.name"]
          - type: move
            from: attributes.namespace
            to: resource["k8s.namespace.name"]
          - type: move
            from: attributes.pod_name
            to: resource["k8s.pod.name"]
          - type: move
            from: attributes.restart_count
            to: resource["k8s.container.restart_count"]
          - type: move
            from: attributes.uid
            to: resource["k8s.pod.uid"]
          # Map to Dynatrace supported timestamp key
          - type: move
            from: attributes["time"]
            to: attributes["timestamp"] # This maps to one of Dynatrace's supported keys
          # Remove unwanted attributes
          - type: remove
            field: attributes["log"] # duplicate value of content/body
          - type: remove
            field: attributes["logtag"] # always the same value
          - type: remove
            field: attributes["time"]


    processors:
      cumulativetodelta: {}
      filter/histogram:
        error_mode: ignore
        metrics:
          metric:
            - "type == METRIC_DATA_TYPE_HISTOGRAM"
      batch:
        send_batch_max_size: 2000
        timeout: 30s
        send_batch_size: 1500
      resource:
        attributes:
          - key: k8s.pod.ip
            action: delete
          - key: k8s.cluster.name
            value: anas-otel
            action: insert
          - key: dt.security_context
            from_attribute: k8s.cluster.name
            action: insert
      attributes:
        actions:
          - key: telemetry.sdk.name
            value: opentelemetry
            action: insert
          - key: dynatrace.otel.collector
            value: dynatrace-logs
            action: insert
      resourcedetection/azure:
        detectors: [env, azure]
        timeout: 2s
        override: false
      k8sattributes:
        auth_type: "serviceAccount"
        passthrough: false
        filter:
          node_from_env_var: KUBE_NODE_NAME
        extract:
          metadata:
            - k8s.namespace.name
            - k8s.deployment.name
            - k8s.daemonset.name
            - k8s.job.name
            - k8s.cronjob.name
            - k8s.replicaset.name
            - k8s.statefulset.name
            - k8s.pod.name
            - k8s.pod.uid
            - k8s.node.name
            - k8s.container.name
            - container.id
            - container.image.name
            - container.image.tag
          labels:
            # Extracts the value of a namespaces label with key `label1` and inserts it as a resource attribute with key `l1`
            - tag_name: app.label.component
              key: app.kubernetes.io/component
              from: pod
        pod_association: # How to associate the data to a pod (order matters)
          - sources: # First try to use the value of the resource attribute k8s.pod.ip
              - from: resource_attribute
                name: k8s.pod.uid
          - sources: # Then try to use the value of the resource attribute k8s.pod.uid
              - from: resource_attribute
                name: k8s.pod.name
          - sources: # If neither of those work, use the request's connection to get the pod IP.
              - from: connection

    exporters:
      otlphttp/dynatrace:
        endpoint: "${env:DT_ENDPOINT}"
        headers:
          Authorization: "Api-Token ${env:DT_API_TOKEN}"
      debug:
        verbosity: detailed
        sampling_initial: 1
        sampling_thereafter: 5

    service:
      telemetry:
        logs:
          level: "info"
        metrics:
          level: "detailed"
      pipelines:
        logs/otlp:
          receivers: [otlp]
          processors:
            [k8sattributes, resourcedetection/azure, resource, attributes, batch]
          exporters: [otlphttp/dynatrace, debug]
        traces:
          receivers: [otlp]
          processors:
            [k8sattributes, resourcedetection/azure, resource, attributes, batch]
          exporters: [otlphttp/dynatrace]
        logs/filelog:
          receivers: [filelog]
          processors:
            [k8sattributes, resourcedetection/azure, resource, attributes, batch]
          exporters: [otlphttp/dynatrace]
        metrics/prometheus:
          receivers: [prometheus]
          processors: [filter/histogram, cumulativetodelta, batch]
          exporters: [otlphttp/dynatrace]
